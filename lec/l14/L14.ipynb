{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS579\n",
    "### Logistic Regression\n",
    "\n",
    "<br><br>\n",
    "#### Illinois Institute of Technology  \n",
    "#### Aron Culotta\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification problem notation:\n",
    "\n",
    "\n",
    "- $\\vec{x} \\in \\mathcal{X}$ &nbsp;&nbsp;&nbsp;&nbsp; *instance*, *example*, *input*\n",
    "  - e.g., an email, a sentence\n",
    "  \n",
    "- $y \\in \\mathcal{Y}$ &nbsp;&nbsp;&nbsp;&nbsp; *target*, *class*, *label*, *output*\n",
    "  - e.g., $y=1$: spam ; $y=-1$: not spam\n",
    "  \n",
    "- $f: \\mathcal{X} \\mapsto \\mathcal{Y}$ &nbsp;&nbsp;&nbsp;&nbsp; *hypothesis*, *learner*, *model*, *classifier*\n",
    "  - e.g., if $x$ contain the word *free*, $y$ is $1$.\n",
    "  \n",
    "  \n",
    "Main quantity of interest: $p(y \\mid \\vec{x})$,  \n",
    "the probability of a class label $y$ given a feature vector $\\vec{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised classification\n",
    "\n",
    "We are given **training data** $D = \\{(\\vec{x}_1, y_1), \\ldots, (\\vec{x}_n, y_n)\\}$\n",
    "\n",
    "||free|money| |*label*|\n",
    "|:--:|:--------:|:--------:|:--:|:--:|\n",
    "||$x_{i1}$|$x_{i2}$| | $y_i$ |\n",
    "|$x_1$|0|0||-1| \n",
    "|$x_2$|1|0|| 1|\n",
    "|$x_3$|1|1||-1|\n",
    "|$x_4$|1|0||-1|\n",
    "|$x_5$|1|1||1|\n",
    "|$x_6$|0|0||1|\n",
    "|$x_7$|0|1||-1|\n",
    "\n",
    "How to classify a new instance?  \n",
    " \"free money\" -> $\\{1,1\\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<u> How can we estimate</u> $p(y \\mid \\vec{x})$?\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "#### Function estimation\n",
    "\n",
    "$p(y \\mid \\vec{x})$ is just a function $f(y, \\vec{x})$ that satisfies three criteria:\n",
    "1. $0 \\le f(y, \\vec{x}) \\le 1$  : values are between 0 and 1\n",
    "2. $\\sum_{y_i} f(y_i, \\vec{x}) = 1$  : values sum to one for all possible classes\n",
    "3. If $f(y_i, \\vec{x}) > f(y_j, \\vec{x})$, then it is more likely that $\\vec{x}$ is of class $i$ than of class $j$\n",
    "\n",
    "\n",
    "How do we ensure criterion 3?\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification as a type of regression\n",
    "\n",
    "Assume our function has some real-valued parameter vector $\\vec{\\theta} = \\{\\theta_1 \\ldots \\theta_k\\}$\n",
    "\n",
    "For simplicity, let's assume there are $k$ terms in our vocabulary, and that each $\\theta$ is associated with a single term.\n",
    "\n",
    "Further, let's assume binary classification, where $y \\in \\{-1, 1\\}$.\n",
    "\n",
    "One simple way to construct a function is as follows:\n",
    "\n",
    "$f(\\vec{x}, \\vec{\\theta}) = \\sum_j x_j \\theta_j = \\vec{x} \\cdot \\vec{\\theta}$  \n",
    "where  \n",
    "- $x_i$ is the frequency of term $j$ in this document.\n",
    "- $\\vec{x} \\cdot \\vec{\\theta}$ is the dot product between vectors $\\vec{x}$ and $\\vec{\\theta}$\n",
    "\n",
    "To classify a document $\\vec{x}$, we can then apply the rule:\n",
    "- If $f(\\vec{x}, \\vec{\\theta}) \\ge 0$\n",
    "  - output $1$\n",
    "- else output $-1$\n",
    "\n",
    "<br><br>\n",
    "Thus,\n",
    "- If $\\theta_j >> 0$ , then term $j$ is associated with the positive class.  \n",
    "- If $\\theta_j << 0$ , then term $j$ is associated with the negative class.\n",
    "<br><br><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import array as npa\n",
    "import numpy as np\n",
    "\n",
    "def f(x, theta):\n",
    "    return np.dot(x.T, theta)\n",
    "\n",
    "x = npa([1,2,3])  # term0 appears 1 time, term1 appears 2 times...\n",
    "theta = npa([-1, -1, 5])  # term 2 predictive of positive class\n",
    "f(x, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-20"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a negative example.\n",
    "x2 = npa([10, 10, 0])\n",
    "f(x2, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be understood as a type of regression task. To fit a regression function, we need to pick a model and an error function, then optimize the model parameters somehow. In machine learning, this is most commonly done with the gradient descent algorithm:\n",
    "\n",
    "** Gradient descent recipe **\n",
    "\n",
    "1.  Select a model type (e.g., linear, polynomial, etc)\n",
    "\n",
    "2.  Select an <span>**error function**</span> that, when minimized, results in a good setting of the model parameters.\n",
    "\n",
    "3.  Analytically determine the gradient of the error function with respect to the model parameters.\n",
    "\n",
    "4.  Iteratively change the parameters by a small amount in the direction of the gradient until the (near) minimum of the error function is found.\n",
    "\n",
    "<br><br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RSS\n",
    "\n",
    "Given a labeled dataset $D = \\{(y_1, \\vec{x}_1) \\ldots (y_n, \\vec{x}_n)\\}$ , an intuitive error function is called  \n",
    "*Residual Sum of Squares*\n",
    "\n",
    "$$\n",
    "RSS(\\vec{\\theta}, D) = \\frac{1}{2}\\sum_{i=1}^{|D|}(y_i - f(\\vec{x}_i, \\vec{\\theta}))^2\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rss(theta, D):\n",
    "    error = 0\n",
    "    for xi, yi in D:\n",
    "        prediction = f(xi, theta)\n",
    "        errori = (yi - prediction)**2\n",
    "        error += errori\n",
    "        print('truth=%g  prediction=%g error=%g' %\n",
    "              (yi, prediction, errori))\n",
    "    return error / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||free|money| |*label*|\n",
    "|:--:|:--------:|:--------:|:--:|:--:|\n",
    "||$x_{i1}$|$x_{i2}$| | $y_i$ |\n",
    "|$x_1$|0|0||-1| \n",
    "|$x_2$|1|0|| 1|\n",
    "|$x_3$|1|1||-1|\n",
    "|$x_4$|1|0||-1|\n",
    "|$x_5$|1|1||1|\n",
    "|$x_6$|0|0||1|\n",
    "|$x_7$|0|1||-1|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0 error=1\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=0 error=1\n",
      "\n",
      "RSS=4\n"
     ]
    }
   ],
   "source": [
    "D = [\n",
    "    (npa([0,0]), -1),\n",
    "    (npa([1,0]), 1),\n",
    "    (npa([1,1]), -1),\n",
    "    (npa([1,1]), -1),\n",
    "    (npa([1,0]), -1),\n",
    "    (npa([1,1]), 1),\n",
    "    (npa([0,0]), 1),\n",
    "    (npa([0,1]), -1),\n",
    "]\n",
    "theta = npa([0,0])\n",
    "print('\\nRSS=%g' % rss(theta, D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=1 error=0\n",
      "truth=-1  prediction=2 error=9\n",
      "truth=-1  prediction=2 error=9\n",
      "truth=-1  prediction=1 error=4\n",
      "truth=1  prediction=2 error=1\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=1 error=4\n",
      "\n",
      "RSS=14.5\n"
     ]
    }
   ],
   "source": [
    "theta = npa([1,1])\n",
    "print('\\nRSS=%g' % rss(theta, D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0.5 error=0.25\n",
      "truth=-1  prediction=-0.5 error=0.25\n",
      "truth=-1  prediction=-0.5 error=0.25\n",
      "truth=-1  prediction=0.5 error=2.25\n",
      "truth=1  prediction=-0.5 error=2.25\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-1 error=0\n",
      "\n",
      "RSS=3.625\n"
     ]
    }
   ],
   "source": [
    "theta = npa([0.5,-1])\n",
    "print('\\nRSS=%g' % rss(theta, D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization problem is then to pick optimal $\\vec{\\theta}^*$ to satisfy:\n",
    "\n",
    "$$ \\vec{\\theta}^* = \\mathrm{argmin}_\\vec{\\theta} \\hspace{.4cm} RSS(\\vec{\\theta}, D)$$\n",
    "\n",
    "<br><br>\n",
    "\n",
    "**Solution:** Gradient descent\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/faq/closed-form-vs-gd/ball.png\">\n",
    "\n",
    "while not converged:\n",
    "1. Compute gradient $\\nabla_\\vec{\\theta}$ of $\\vec{\\theta}$ w.r.t. RSS\n",
    "2. Change $\\vec{\\theta}$ in direction of $\\nabla_\\vec{\\theta}$\n",
    "\n",
    "\n",
    "$$\\nabla_\\vec{\\theta} = \\{\\frac{\\partial RSS(f, D)}{\\partial \\theta_1} \\ldots \\frac{\\partial RSS(f, D)}{\\partial \\theta_v}\\}$$\n",
    "\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial RSS(f, D)}{\\partial \\theta_j} &=& \\frac{\\partial}{\\partial \\theta_j} \\frac{1}{2}\\sum_{i=1}^{|D|}(y_i - \\vec{\\theta} \\cdot \\vec{x}_i)^2\\\\\n",
    "&=& \\sum_{i=1}^{|D|}(y_i - \\vec{\\theta} \\cdot \\vec{x}_i)\\frac{\\partial}{\\partial \\theta_j} (y_i - \\theta \\cdot \\vec{x}_i)\\\\\n",
    "&=& \\sum_{i=1}^{|D|}(y_i - \\vec{\\theta} \\cdot \\vec{x}_i)(-x_{ij})\\end{aligned}\n",
    "\n",
    "<br><br>\n",
    "**To update parameters:**\n",
    "\n",
    "$$\\vec{\\theta}_j^{t+1} = \\vec{\\theta}_j^{t} + \\eta \\sum_{i=1}^{|D|}(y_i - \\vec{\\theta}^t \\cdot \\vec{x}_i)x_{ij}$$\n",
    "\n",
    "$\\eta$ = \"learning rate\", to prevent \"jumping over\" minimum\n",
    "\n",
    "<br>\n",
    "\n",
    "What is this update doing?\n",
    "<br><br><br>\n",
    "- Compute error on $i$th example\n",
    "- Adjust parameter $j$ to reduce that error, proportional to how important feature $j$ is for example $i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient(theta, D):\n",
    "    result = np.zeros(len(theta), dtype=np.float64)\n",
    "    for xi, yi in D:\n",
    "        error = yi - f(xi, theta)\n",
    "        for j, xij in enumerate(xi):\n",
    "            result[j] += error * -xij\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient(npa([0,0]), D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0 error=1\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=0 error=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rss(npa([0, 0]), D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=-1 error=4\n",
      "truth=-1  prediction=-3 error=4\n",
      "truth=-1  prediction=-3 error=4\n",
      "truth=-1  prediction=-1 error=0\n",
      "truth=1  prediction=-3 error=16\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-2 error=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.5"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rss(npa([-1, -2]), D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def gradient_descent(gradient_fn, error_fn, theta,\n",
    "                     learning_rate, D,\n",
    "                     tolerance, max_iters):\n",
    "    errori = error_fn(theta, D)\n",
    "    iters = 0\n",
    "    all_errors = [errori]\n",
    "    while True:\n",
    "        iters += 1\n",
    "        print('\\n\\niteration %d' % iters)\n",
    "        grad = gradient_fn(theta, D)\n",
    "        theta -= learning_rate * grad  # UPDATE!\n",
    "        newerror = error_fn(theta, D)\n",
    "        all_errors.append(newerror)\n",
    "        print('old error=%g   new error=%g  theta=%s\\n\\n' %\n",
    "              (errori, newerror, str(theta)))\n",
    "        error_diff = errori - newerror\n",
    "        if error_diff < 0 or errori - newerror < tolerance \\\n",
    "            or iters >= max_iters:\n",
    "            break\n",
    "        else:\n",
    "            errori = newerror\n",
    "            \n",
    "    plt.plot(all_errors, 'bo-')\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('error')\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=1 error=0\n",
      "truth=-1  prediction=2 error=9\n",
      "truth=-1  prediction=2 error=9\n",
      "truth=-1  prediction=1 error=4\n",
      "truth=1  prediction=2 error=1\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=1 error=4\n",
      "\n",
      "\n",
      "iteration 1\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=-0.8 error=3.24\n",
      "truth=-1  prediction=-1.6 error=0.36\n",
      "truth=-1  prediction=-1.6 error=0.36\n",
      "truth=-1  prediction=-0.8 error=0.04\n",
      "truth=1  prediction=-1.6 error=6.76\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-0.8 error=0.04\n",
      "old error=14.5   new error=6.4  theta=[-0.8 -0.8]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 2\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0.28 error=0.5184\n",
      "truth=-1  prediction=0.2 error=1.44\n",
      "truth=-1  prediction=0.2 error=1.44\n",
      "truth=-1  prediction=0.28 error=1.6384\n",
      "truth=1  prediction=0.2 error=0.64\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-0.08 error=0.8464\n",
      "old error=6.4   new error=4.2616  theta=[ 0.28 -0.08]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 3\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=-0.152 error=1.3271\n",
      "truth=-1  prediction=-0.736 error=0.069696\n",
      "truth=-1  prediction=-0.736 error=0.069696\n",
      "truth=-1  prediction=-0.152 error=0.719104\n",
      "truth=1  prediction=-0.736 error=3.0137\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-0.584 error=0.173056\n",
      "old error=4.2616   new error=3.68618  theta=[-0.152 -0.584]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 4\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0.1504 error=0.72182\n",
      "truth=-1  prediction=-0.2752 error=0.525335\n",
      "truth=-1  prediction=-0.2752 error=0.525335\n",
      "truth=-1  prediction=0.1504 error=1.32342\n",
      "truth=1  prediction=-0.2752 error=1.62614\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-0.4256 error=0.329935\n",
      "old error=3.68618   new error=3.52599  theta=[ 0.1504 -0.4256]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 5\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0.05536 error=0.892345\n",
      "truth=-1  prediction=-0.52 error=0.2304\n",
      "truth=-1  prediction=-0.52 error=0.2304\n",
      "truth=-1  prediction=0.05536 error=1.11378\n",
      "truth=1  prediction=-0.52 error=2.3104\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-0.57536 error=0.180319\n",
      "old error=3.52599   new error=3.47882  theta=[ 0.05536 -0.57536]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 6\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0.145216 error=0.730656\n",
      "truth=-1  prediction=-0.403072 error=0.356323\n",
      "truth=-1  prediction=-0.403072 error=0.356323\n",
      "truth=-1  prediction=0.145216 error=1.31152\n",
      "truth=1  prediction=-0.403072 error=1.96861\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-0.548288 error=0.204044\n",
      "old error=3.47882   new error=3.46374  theta=[ 0.145216 -0.548288]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 7\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0.128973 error=0.758688\n",
      "truth=-1  prediction=-0.467814 error=0.283222\n",
      "truth=-1  prediction=-0.467814 error=0.283222\n",
      "truth=-1  prediction=0.128973 error=1.27458\n",
      "truth=1  prediction=-0.467814 error=2.15448\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-0.596787 error=0.162581\n",
      "old error=3.46374   new error=3.45839  theta=[ 0.1289728 -0.5967872]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.1289728, -0.5967872])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110a6e1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "theta = npa([1.,1.])\n",
    "gradient_descent(gradient, rss, theta,\n",
    "                 .2, D, .01, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From regression to classification\n",
    "\n",
    "**Does our error function make sense?**\n",
    "\n",
    "\n",
    "iteration 1  \n",
    "truth=-1  prediction=0 error=1  \n",
    "truth=1  prediction=-0.8 error=3.24  \n",
    "**truth=-1  prediction=-1.6 error=0.36**\n",
    "\n",
    "<br><br>\n",
    "\n",
    "The above assumes that the output variable $y_i$ is a real number. Thus, this is a model of <span>**regression**</span>.  \n",
    "\n",
    "When $y$ is disrete, the problem is one of <span>**classification**</span>.  \n",
    "\n",
    "<br>\n",
    "Recall our three criterion for the function:\n",
    "1. $0 \\le f(y, \\vec{x}) \\le 1$  : values are between 0 and 1\n",
    "2. $\\sum_{y_i} f(y_i, \\vec{x}) = 1$  : values sum to one for all possible classes\n",
    "3. If $f(y_i, \\vec{x}) > f(y_j, \\vec{x})$, then it is more likely that $\\vec{x}$ is of class $i$ than of class $j$\n",
    "\n",
    "<br>\n",
    "We have satisfied 3 (mostly), but not 1 or 2.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "The way around this is to change our model. Rather than regression, we need classification. We can do this by passing the dot product $x_i \\cdot \\theta$ through a “squashing function” (the **logistic function**) that ensures its value is always between 0 and 1: \n",
    "\n",
    "$$f(\\vec{x}_i, \\vec{\\theta}) = \\frac{1}{1 + e^{-\\vec{x}_i \\cdot \\vec{\\theta}}}$$\n",
    "\n",
    "This is called **logistic regression.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf4AAAGACAYAAABMRwCUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f8e6828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from math import exp\n",
    "def logistic(x, theta):\n",
    "    return 1 / (1 + exp(-f(x, theta)))\n",
    "    \n",
    "x = npa([1])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(range(-10, 10), [logistic(x, theta) for theta in range(-10, 10)])\n",
    "plt.xlabel('theta', size=20)\n",
    "plt.ylabel('logistic', size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because $f(x_i, \\vec{\\theta})$ will always be between 0 and 1, and will sum to one for both classes, we have the right to call this a <span>**probability**</span> $p(y_i=1|\\vec{x}_i)$.  \n",
    "\n",
    "$$f(\\vec{x}_i) = p(y_i=1|\\vec{x}_i) = \\frac{1}{1 + e^{-\\vec{x}_i \\cdot \\vec{\\theta}}}$$\n",
    "\n",
    "and, for binary classification, the probability of a negative example:\n",
    "\n",
    "$$\n",
    "p(y_i=-1|\\vec{x}_i) = 1 - p(y_i=1|\\vec{x}_i)\n",
    "$$\n",
    "\n",
    "with some algebra, it turns out that:\n",
    "\n",
    "$$\n",
    "p(y_i=-1|\\vec{x}_i) = \\frac{1}{1 + e^{\\vec{x}_i \\cdot \\vec{\\theta}}}\n",
    "$$\n",
    "\n",
    "Because of this, if $y_i \\in \\{-1, 1\\}$, we can write:\n",
    "\n",
    "$$\n",
    "p(y_i|\\vec{x}_i) =  \\frac{1}{1 + e^{-y_i \\vec{x}_i \\cdot \\vec{\\theta}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is a good error function for logistic regression?**\n",
    "\n",
    "We can now rephrase our learning objective as maximizing the <span>*joint probability of the true labels for all training instances.*</span>  \n",
    "\n",
    "Since we assume each instance is drawn independently, we can write this joint probability as a product of individual probabilities: \n",
    "\n",
    "$$p(y_1 \\ldots y_n|\\vec{x}_1 \\ldots \\vec{x}_n) = p(y_1|\\vec{x}_n) * p(y_2|\\vec{x}_2) * \\ldots * p(y_n|\\vec{x}_n) = \\prod_{i=1}^{n}p(y_i|\\vec{x}_i)$$\n",
    "\n",
    "Because we’re used to minimizing functions using gradient descent, rather than maximizing the probability, we can instead minimize the negative probability. This is our new error function: \n",
    "\n",
    "$$\n",
    "E(D, h) = - \\prod_{i=1}^{n}p(y_i|x_i)\n",
    "$$\n",
    "\n",
    "Note that this is very similar to RSS, but by using probabilities, we ensure that the output for each instance is always between 0 and 1.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "Following our learning recipe, our next step is to minimize $E(D,h)$ using gradient descent.  \n",
    "\n",
    "Computing the gradient of $E(D,h)$ in its current form is rather hard. So, we can simply transform it to something that’s easier to take the gradient of: \n",
    "\n",
    "$$E(D,h) = - \\ln \\prod_{i=1}^n  p(y_i|\\vec{x}_i) = -\\sum_i \\ln p(y_i|\\vec{x}_i)$$\n",
    "\n",
    "This is called the <span>**negative log likelihood**</span>. It turns out that minimizing $f(x)$ or $\\ln f(x)$ results in the same answer, so we can make this transformation without affecting our final solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def nll(theta, D):\n",
    "    total = 0\n",
    "    for xi, yi in D:\n",
    "        pred = logistic(xi, theta) if yi==1 else 1-logistic(xi, theta)\n",
    "        print('truth=%g  pr(true label)=%g' % \n",
    "              (yi, pred))\n",
    "        total += log(pred)\n",
    "    return -total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we’re ready to calculate the gradient with respect to one parameter $\\theta_j$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial E(D,f)}{\\partial \\theta_j} & = & \\frac{\\partial}{\\partial \\theta_j}- \\ln \\prod_i \\frac{1}{1 + e^{-y_i x_i \\cdot \\theta}} \\\\\n",
    "& = &  \\frac{\\partial}{\\partial \\theta_j}-  \\sum_i \\ln \\frac{1}{1 + e^{-y_i x_i \\cdot \\theta}} \\quad \\hbox{(by definition of log of products)}\\\\\n",
    "& = &  -  \\sum_i 1 + e^{-y_i x_i \\cdot \\theta} \\frac{\\partial}{\\partial \\theta_j} \\frac{1}{1 + e^{-y_i x_i \\cdot \\theta}} \\quad  \\hbox{  (by }\\frac{d}{dx}\\ln(f(x)) = \\frac{1}{f(x)} \\frac{d}{dx}f(x) ) \\\\\n",
    "& = &  -  \\sum_i (1 + e^{-y_i x_i \\cdot \\theta})\\Big(\\frac{-y_ix_{ij} e^{-y_ix_i \\cdot \\theta}}{(1 + e^{-y_ix_i\\cdot \\theta})^2}\\Big) \\quad \\hbox{    (by quotient and chain rules) }\\\\\n",
    "& = & - \\sum_i \\frac{-y_i x_{ij} e^{-y_i x_i \\cdot \\theta}}{1 + e^{-y_i x_i \\cdot \\theta}} \\quad \\hbox{     (by algebra) }\\\\\n",
    "& = & \\sum_i y_i x_{ij} (1 - p(y_i | x_i)) \\quad \\Big( \\hbox{by }\\frac{e^{-y_i x_i \\cdot \\theta}}{1 + e^{-y_i x_i \\cdot \\theta}} = 1 - p(y_i|x_i) \\Big)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Thus, the final logistic regression update is: \n",
    "\n",
    "$$\n",
    "\\theta_j^{t+1} \\leftarrow \\theta_j^{t} + \\eta \\sum_i y_i x_{ij}(1-p(y_i|\\vec{x}_i))\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_logistic(theta, D):\n",
    "    result = np.zeros(len(theta), dtype=np.float64)\n",
    "    for xi, yi in D:\n",
    "        pred = logistic(xi, theta) if yi==1 else 1-logistic(xi, theta)\n",
    "        error = yi * pred\n",
    "        for j, xij in enumerate(xi):\n",
    "            result[j] += error * xij\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.731059\n",
      "truth=-1  pr(true label)=0.119203\n",
      "truth=-1  pr(true label)=0.119203\n",
      "truth=-1  pr(true label)=0.268941\n",
      "truth=1  pr(true label)=0.880797\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.268941\n",
      "\n",
      "\n",
      "iteration 1\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.708797\n",
      "truth=-1  pr(true label)=0.135614\n",
      "truth=-1  pr(true label)=0.135614\n",
      "truth=-1  pr(true label)=0.291203\n",
      "truth=1  pr(true label)=0.864386\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.276347\n",
      "old error=8.70686   new error=8.39193  theta=[ 0.88954916  0.96265502]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 2\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.687504\n",
      "truth=-1  pr(true label)=0.151942\n",
      "truth=-1  pr(true label)=0.151942\n",
      "truth=-1  pr(true label)=0.312496\n",
      "truth=1  pr(true label)=0.848058\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.282727\n",
      "old error=8.39193   new error=8.12073  theta=[ 0.78847403  0.930974  ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 3\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.667424\n",
      "truth=-1  pr(true label)=0.167788\n",
      "truth=-1  pr(true label)=0.167788\n",
      "truth=-1  pr(true label)=0.332576\n",
      "truth=1  pr(true label)=0.832212\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.288059\n",
      "old error=8.12073   new error=7.88988  theta=[ 0.69655599  0.9048294 ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 4\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.648718\n",
      "truth=-1  pr(true label)=0.182817\n",
      "truth=-1  pr(true label)=0.182817\n",
      "truth=-1  pr(true label)=0.351282\n",
      "truth=1  pr(true label)=0.817183\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.292355\n",
      "old error=7.88988   new error=7.69544  theta=[ 0.61340767  0.88397173]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 5\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.631466\n",
      "truth=-1  pr(true label)=0.196777\n",
      "truth=-1  pr(true label)=0.196777\n",
      "truth=-1  pr(true label)=0.368534\n",
      "truth=1  pr(true label)=0.803223\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.29566\n",
      "old error=7.69544   new error=7.53326  theta=[ 0.53850913  0.86805228]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 6\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.615679\n",
      "truth=-1  pr(true label)=0.209507\n",
      "truth=-1  pr(true label)=0.209507\n",
      "truth=-1  pr(true label)=0.384321\n",
      "truth=1  pr(true label)=0.790493\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.298039\n",
      "old error=7.53326   new error=7.39923  theta=[ 0.47124912  0.85665135]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 7\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.601319\n",
      "truth=-1  pr(true label)=0.220927\n",
      "truth=-1  pr(true label)=0.220927\n",
      "truth=-1  pr(true label)=0.398681\n",
      "truth=1  pr(true label)=0.779073\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.299578\n",
      "old error=7.39923   new error=7.28939  theta=[ 0.4109653   0.84930736]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 8\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.588309\n",
      "truth=-1  pr(true label)=0.231027\n",
      "truth=-1  pr(true label)=0.231027\n",
      "truth=-1  pr(true label)=0.411691\n",
      "truth=1  pr(true label)=0.768973\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.300369\n",
      "old error=7.28939   new error=7.20017  theta=[ 0.35697953  0.84554326]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 9\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.57655\n",
      "truth=-1  pr(true label)=0.239848\n",
      "truth=-1  pr(true label)=0.239848\n",
      "truth=-1  pr(true label)=0.42345\n",
      "truth=1  pr(true label)=0.760152\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.300506\n",
      "old error=7.20017   new error=7.12833  theta=[ 0.30862573  0.84488814]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 10\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.565931\n",
      "truth=-1  pr(true label)=0.247468\n",
      "truth=-1  pr(true label)=0.247468\n",
      "truth=-1  pr(true label)=0.434069\n",
      "truth=1  pr(true label)=0.752532\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.300085\n",
      "old error=7.12833   new error=7.07108  theta=[ 0.26527013  0.84689312]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 11\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.556341\n",
      "truth=-1  pr(true label)=0.253986\n",
      "truth=-1  pr(true label)=0.253986\n",
      "truth=-1  pr(true label)=0.443659\n",
      "truth=1  pr(true label)=0.746014\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.299193\n",
      "old error=7.07108   new error=7.026  theta=[ 0.2263242   0.85114197]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 12\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.547668\n",
      "truth=-1  pr(true label)=0.259512\n",
      "truth=-1  pr(true label)=0.259512\n",
      "truth=-1  pr(true label)=0.452332\n",
      "truth=1  pr(true label)=0.740488\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.297913\n",
      "old error=7.026   new error=6.99103  theta=[ 0.19125179  0.85725705]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 13\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.539808\n",
      "truth=-1  pr(true label)=0.264157\n",
      "truth=-1  pr(true label)=0.264157\n",
      "truth=-1  pr(true label)=0.460192\n",
      "truth=1  pr(true label)=0.735843\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.296316\n",
      "old error=6.99103   new error=6.96444  theta=[ 0.15957171  0.86490179]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 14\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.532668\n",
      "truth=-1  pr(true label)=0.268031\n",
      "truth=-1  pr(true label)=0.268031\n",
      "truth=-1  pr(true label)=0.467332\n",
      "truth=1  pr(true label)=0.731969\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.294468\n",
      "old error=6.96444   new error=6.94478  theta=[ 0.13085709  0.87378049]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 15\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.526159\n",
      "truth=-1  pr(true label)=0.271234\n",
      "truth=-1  pr(true label)=0.271234\n",
      "truth=-1  pr(true label)=0.473841\n",
      "truth=1  pr(true label)=0.728766\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.292425\n",
      "old error=6.94478   new error=6.93083  theta=[ 0.10473274  0.8836365 ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 16\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.520207\n",
      "truth=-1  pr(true label)=0.273861\n",
      "truth=-1  pr(true label)=0.273861\n",
      "truth=-1  pr(true label)=0.479793\n",
      "truth=1  pr(true label)=0.726139\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.290234\n",
      "old error=6.93083   new error=6.92157  theta=[ 0.08087117  0.89424926]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.08087117,  0.89424926])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cebc908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "theta = npa([1.,1.])\n",
    "gradient_descent(gradient_logistic, nll, theta, \n",
    "                 .1, D, .01, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.731059\n",
      "truth=-1  pr(true label)=0.119203\n",
      "truth=-1  pr(true label)=0.119203\n",
      "truth=-1  pr(true label)=0.268941\n",
      "truth=1  pr(true label)=0.880797\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.268941\n",
      "\n",
      "\n",
      "iteration 1\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.476651\n",
      "truth=-1  pr(true label)=0.368927\n",
      "truth=-1  pr(true label)=0.368927\n",
      "truth=-1  pr(true label)=0.523349\n",
      "truth=1  pr(true label)=0.631073\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.347446\n",
      "old error=8.70686   new error=6.28656  theta=[-0.09346331  0.63028469]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 2\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.514616\n",
      "truth=-1  pr(true label)=0.242605\n",
      "truth=-1  pr(true label)=0.242605\n",
      "truth=-1  pr(true label)=0.485384\n",
      "truth=1  pr(true label)=0.757395\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.253512\n",
      "old error=6.28656   new error=7.2563  theta=[ 0.05848152  1.07997036]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.05848152,  1.07997036])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110a317f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What if learning rate too big?\n",
    "theta = npa([1.,1.])\n",
    "gradient_descent(gradient_logistic, nll, theta,\n",
    "                 .99, D, .01, 50)\n",
    "# We stop too early!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## Supervised Classification Workflow\n",
    "\n",
    "1. **Collect** raw data: emails\n",
    "2. Manually **categorize** them:  spam or not\n",
    "3. **Vectorize**: email -> word counts [**features**]\n",
    "4. **Train** / **Fit**: create $f(x)$\n",
    "5. **Collect** new raw data\n",
    "6. **Predict**: compute $f(x)$ for new $x$\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Steps 1 & 2: Collect and categorize\n",
    "\n",
    "**Spam:**\n",
    "\n",
    "> Free credit report!\n",
    "\n",
    "\n",
    "> Free money!\n",
    "\n",
    "\n",
    "**Not spam:**\n",
    "\n",
    "> Are you free tonight?\n",
    "\n",
    "> How are you?\n",
    "\n",
    "\n",
    "##### Step 3: Vectorize\n",
    "\n",
    "> 'Free money!'\n",
    "\n",
    "becomes\n",
    "\n",
    "```\n",
    "free: 1\n",
    "money: 1\n",
    "!: 1\n",
    "?: 0\n",
    "credit: 0\n",
    "...\n",
    "```\n",
    "\n",
    "**Representation**: \"Feature engineering is the key\" -- Domingos\n",
    "\n",
    "##### Step 4: Train/Fit\n",
    "\n",
    "Which model to use?\n",
    "\n",
    "- Naive Bayes\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- K-Nearest Neighbors\n",
    "- Support Vector Machines\n",
    "- ... many many more\n",
    "\n",
    "##### Steps 5-6: Predict on new data\n",
    "\n",
    "> Free vacation!\n",
    "\n",
    "**Spam**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalization\n",
    "\n",
    "How accurate will I be on a new, unobserved example?\n",
    "\n",
    "How do you know if it works?\n",
    "\n",
    "1. Train on data ${\\mathcal D_1}$\n",
    "2. Predict on data ${\\mathcal D_2}$\n",
    "3. Compute accuracy on ${\\mathcal D_2}$.\n",
    "   - Why not ${\\mathcal D_1}$?\n",
    "   \n",
    "   \n",
    "How do you know if it works?\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "1. Train on data ${\\mathcal D_1}$\n",
    "2. Predict on data ${\\mathcal D_2}$\n",
    "3. Compute accuracy on ${\\mathcal D_2}$.\n",
    "4. Tweak algorithm / representation\n",
    "5. Repeat\n",
    "\n",
    "How many times can I do this?\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "#### Measuring Generalization\n",
    "\n",
    "Rather than estimate our accuracy using one train/test split, we can get more robust estimates of accuracy by averaging over many samples:\n",
    "\n",
    "\n",
    "- $k$-fold cross-validation:\n",
    "  - Split data into $k$ equal sized groups. \n",
    "  - Train on all but one group and test on the remainder.\n",
    "  - Repeat $k$ times.\n",
    "\n",
    "E.g., 10-fold cross-validation:\n",
    "  - train on 90%, test on 10%, repeat 10 x's\n",
    "       - each example appears only once in test set\n",
    "       \n",
    "E.g.,\n",
    "$D = [1,2,3,\\ldots,20]$\n",
    "\n",
    "- Split 1: $D_\\mathrm{train} = [1\\ldots18], D_\\mathrm{test}=[19,20]$\n",
    "- Split 2: $D_\\mathrm{train} = [1\\ldots16,19,20], D_\\mathrm{test}=[17,18]$\n",
    "- ...\n",
    "- Split 10: $D_\\mathrm{train} = [3\\ldots20], D_\\mathrm{test}=[1,2]$\n",
    "\n",
    "       \n",
    "## Improved Experimental Design\n",
    "\n",
    "1. Collect data\n",
    "2. Build model\n",
    "3. Compute cross-validation accuracy\n",
    "4. Tune model\n",
    "5. Go to 3\n",
    "6. **Report accuracy on new data** <- Best estimate of generalization accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example of text classification using scikit-learn\n",
    "\n",
    "Below, we'll see an example of this process for document classification.\n",
    "\n",
    "Task: classify a newsgroup post by category\n",
    "\n",
    "  http://qwone.com/~jason/20Newsgroups/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comp.os.ms-windows.misc', 'comp.sys.mac.hardware']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['comp.os.ms-windows.misc', 'comp.sys.mac.hardware']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                      categories=categories,\n",
    "                                      remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 1169 documents\n"
     ]
    }
   ],
   "source": [
    "print('read %d documents' % len(newsgroups_train.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"===============================================================================\\n \\tI'm looking for the E_Mail Address of the Caere Corporation. \\n\\tTheir Address is:\\n\\n\\tCAERE CORPORATION\\n\\t100 COOPER COURT\\n\\tLOS GATOS\\n\\tCALIFONIA 95030\\n\\n\\tIf you know the address  o  have access to find it. Please could\\n\\tyou send it to me.    \\n\\n\\tMy E_Mail Address is:\\n\\n\\t\\t<zia@uk.ac.ed.castle>\\n\\n\\tThanking you in advance,\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class labels=Counter({0: 591, 1: 578})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print('class labels=%s' % str(Counter(newsgroups_train.target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1169, 38537)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert into feature matrix.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(newsgroups_train.data)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Vector Matrix\n",
    "\n",
    "Create a matrix $X$ where $X[i,j]$ is the frequency of term $j$ in document $i$.\n",
    "\n",
    "$$\n",
    "X = \\begin{pmatrix}\n",
    "~ & \\hbox{term}_1 & \\hbox{term}_2 & \\hbox{term}_3 & \\hbox{term}_4 \\\\\n",
    "\\hbox{doc}_1 & 1  &  0  &  0 & 0 \\\\\n",
    "\\hbox{doc}_2 & 0  &  0  &  0 & 2 \\\\\n",
    "\\hbox{doc}_3 & 1  &  1  &  0 & 0 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Feature matrices are mostly 0 for NLP problems\n",
    "\n",
    "## Compressed Sparse Row (CSR) Matrix\n",
    "\n",
    "\n",
    "$$\n",
    "X = \\begin{pmatrix}\n",
    "~ & \\hbox{term}_1 & \\hbox{term}_2 & \\hbox{term}_3 & \\hbox{term}_4 \\\\\n",
    "\\hbox{doc}_1 & 1  &  0  &  0 & 0 \\\\\n",
    "\\hbox{doc}_2 & 0  &  0  &  0 & 2 \\\\\n",
    "\\hbox{doc}_3 & 1  &  1  &  0 & 0 \\\\\n",
    "\\hbox{doc}_4 & 1  &  0  &  0 & 0 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "CSR Matrix is an object with three attributes: \n",
    "- **val:** $\\{1,2,1,1,1\\}$  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *list of all non-zero values*  \n",
    "- **col_ind:** $\\{0,3,0,1,0\\}$ &nbsp; *column index for each non-zero value* (e.g., first non-zero value (1) is in column 0) \n",
    "- **row_ptr:** $\\{0,1,2,4\\}$ &nbsp;&nbsp;&nbsp; *index into **col_ind** where each row starts* (e.g., tweet3, term1 corresponds to col_ind[2])\n",
    "\n",
    "Allows efficient row access (good for us, since each row is a document).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x38537 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 38 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9329, 19189, 33013, 11925, 14707,  9170, 34019, 38090, 25239,\n",
       "       23579, 31191, 12925, 27815, 19603, 16048, 33236,  9201, 17869,\n",
       "       21094, 37564, 18957,  7771, 11857, 16930, 22088, 12941, 12871,\n",
       "         733, 19556, 33022, 12903, 11836, 26576,  9294, 14616, 33021,\n",
       "       16301, 22073], dtype=int32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which word indices are in the first document?\n",
    "X[0].nonzero()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['advance', 'in', 'thanking', 'castle', 'ed', 'ac', 'uk', 'zia',\n",
       "       'my', 'me', 'send', 'could', 'please', 'it', 'find', 'to', 'access',\n",
       "       'have', 'know', 'you', 'if', '95030', 'califonia', 'gatos', 'los',\n",
       "       'court', 'cooper', '100', 'is', 'their', 'corporation', 'caere',\n",
       "       'of', 'address', 'e_mail', 'the', 'for', 'looking'],\n",
       "      dtype='<U79')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "features = np.array(vec.get_feature_names())\n",
    "features[X[0].nonzero()[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 3, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 4, 2, 3, 1, 1])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the word frequencies?\n",
    "X[0].data\n",
    "# e.g., \"address\" occurs 4 times in the first document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "935 training instances and 234 testing instances\n",
      "935 training instances and 234 testing instances\n",
      "935 training instances and 234 testing instances\n",
      "935 training instances and 234 testing instances\n",
      "936 training instances and 233 testing instances\n",
      "percent incorrect=0.15\n"
     ]
    }
   ],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "y = newsgroups_train.target\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "preds = []\n",
    "truths = []\n",
    "for train, test in kfold.split(X):\n",
    "    print('%d training instances and %d testing instances' %\n",
    "         (len(train), len(test)))\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X[train], y[train])\n",
    "    preds.extend(clf.predict(X[test]))\n",
    "    truths.extend(y[test])\n",
    "\n",
    "n_errors = np.sum(np.abs(np.array(preds) - np.array(truths)))\n",
    "print('percent incorrect=%.2f' % (n_errors / len(y)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
